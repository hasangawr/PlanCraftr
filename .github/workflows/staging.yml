name: "Staging env provision & configure"
on:
  push:
    branches:
      - dev
  pull_request:
    branches:
      - dev
permissions:
  id-token: write # This is required for aws oidc connection
  contents: read # This is required for actions/checkout
  pull-requests: write # This is required for gh bot to comment PR
env:
  TF_LOG: INFO
  AWS_REGION: ${{ secrets.AWS_REGION }}
jobs:
  provision_and_configure:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash
        working-directory: ./infrastructure/terraform/staging/
    steps:
      - name: Git checkout
        uses: actions/checkout@v3

      - name: Configure AWS credentials from AWS account
        uses: aws-actions/configure-aws-credentials@v1
        with:
          role-to-assume: ${{ secrets.AWS_ROLE }}
          aws-region: ${{ secrets.AWS_REGION }}
          role-session-name: GitHub-OIDC-TERRAFORM

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.2.5

      - name: Terraform fmt
        id: fmt
        run: terraform fmt -check
        continue-on-error: true

      - name: Terraform Init
        id: init
        env:
          AWS_BUCKET_NAME: ${{ secrets.AWS_TF_STATE_S3_BUCKET_NAME }}
          AWS_BUCKET_KEY_NAME: ${{ secrets.AWS_TF_STATE_S3_BUCKET_KEY_NAME }}
        run: terraform init -backend-config="bucket=${AWS_BUCKET_NAME}" -backend-config="key=${AWS_BUCKET_KEY_NAME}" -backend-config="region=${AWS_REGION}"

      - name: Terraform Validate
        id: validate
        run: terraform validate -no-color

      - name: Terraform Plan
        id: plan
        run: terraform plan -no-color
        if: github.event_name == 'pull_request'
        continue-on-error: true

      - uses: actions/github-script@v6
        if: github.event_name == 'pull_request'
        env:
          PLAN: "terraform\n${{ steps.plan.outputs.stdout }}"
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const output = `#### Terraform Format and Style üñå\`${{ steps.fmt.outcome }}\`
            #### Terraform Initialization ‚öôÔ∏è\`${{ steps.init.outcome }}\`
            #### Terraform Validation ü§ñ\`${{ steps.validate.outcome }}\`
            <details><summary>Validation Output</summary>

            \`\`\`\n
            ${{ steps.validate.outputs.stdout }}
            \`\`\`

            </details>

            #### Terraform Plan üìñ\`${{ steps.plan.outcome }}\`

            <details><summary>Show Plan</summary>

            \`\`\`\n
            ${process.env.PLAN}
            \`\`\`

            </details>

            *Pushed by: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

      - name: Terraform Plan Status
        if: steps.plan.outcome == 'failure'
        run: exit 1

      - name: Terraform Apply
        id: apply
        if: github.ref == 'refs/heads/dev' && github.event_name == 'push'
        run: terraform apply -auto-approve -input=false

      - name: Get ec2 public ip
        id: ec2_ip
        if: steps.apply.outcome == 'success'
        env:
          TF_LOG: ""
        run: |
          echo "Raw Terraform output:"
          EC2_PUBLIC_IP=$(terraform output -raw staging_public_ip | tr -d '\n' | cut -d ':' -f 1 | awk -F 'staging_public_ip' '{print $2}')
          echo "EC2_PUBLIC_IP=$EC2_PUBLIC_IP" >> $GITHUB_ENV

      - name: Configure ec2 instance
        id: configure_ec2
        if: steps.ec2_ip.outcome == 'success'
        env:
          EC2_PUBLIC_IP: ${{ env.EC2_PUBLIC_IP }}
          SSH_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
          ENV_VARIABLES: ${{ secrets.STAGING_ENV }}
        run: |
          # Add SSH key to the SSH agent
          mkdir ~/.ssh/
          echo "${SSH_KEY}" > ec2_key.pem
          chmod 600 ec2_key.pem
          ssh-keyscan -H $EC2_PUBLIC_IP > ~/.ssh/known_hosts

          # create and copy .env file to remote ec2 instance
          echo "$ENV_VARIABLES" > .env
          scp -i ec2_key.pem .env ubuntu@$EC2_PUBLIC_IP:~/

          ssh -i ec2_key.pem ubuntu@$EC2_PUBLIC_IP << 'EOF'
            # Update & Upgrade
            sudo apt update -y && sudo apt upgrade -y

            # Install Node.js
            curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
            sudo apt-get install -y nodejs

            # Install pm2
            sudo npm install pm2 -g

            # Clone the repository
            mkdir -p ~/app && cd ~/app
            git clone https://github.com/hasangawr/PlanCraftr.git .
            cd backend

            # Set up environment and install dependencies
            mv ~/.env ~/app/backend/
            npm install
            npm run build

            # Start the app using pm2
            pm2 start "npm run start"

            # Configure pm2 to be persistent
            sudo env PATH=$PATH:/usr/bin /usr/lib/node_modules/pm2/bin/pm2 startup systemd -u ubuntu --hp /home/ubuntu
            pm2 save

            # Install Caddy for reverse proxy
            sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https curl
            curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg
            curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list
            sudo apt update
            sudo apt install -y caddy

            # Change default Caddyfile permission
            sudo chmod 666 /etc/caddy/Caddyfile

            # Configure Caddy reverse proxy
            echo "staging.api.plancraftr.com {
              reverse_proxy localhost:3000
            }" | sudo tee /etc/caddy/Caddyfile

            # Start Caddy
            sudo systemctl enable caddy
            sudo systemctl start caddy
            sudo systemctl restart caddy
          EOF

  deploy_to_s3:
    runs-on: ubuntu-latest
    needs: provision_and_configure
    if: github.ref == 'refs/heads/dev' && github.event_name == 'push'
    defaults:
      run:
        shell: bash
        working-directory: ./infrastructure/terraform/staging/
    steps:
      - name: Git checkout
        uses: actions/checkout@v3

      - name: Configure AWS credentials from AWS account
        uses: aws-actions/configure-aws-credentials@v1
        with:
          role-to-assume: ${{ secrets.AWS_ROLE }}
          aws-region: ${{ secrets.AWS_REGION }}
          role-session-name: GitHub-OIDC-TERRAFORM

      - name: Install dependencies and build
        run: |
          npm install
          npm run build

      - name: Deploy to S3
        run: |
          aws s3 sync ./dist s3://www.staging.plancraftr.com --delete

  # # destroy_after_delay:
  # #   runs-on: ubuntu-latest
  # #   needs: provision_and_configure
  # #   if: github.ref == 'refs/heads/dev' && github.event_name == 'push'
  # #   defaults:
  # #     run:
  # #       shell: bash
  # #       working-directory: ./infrastructure/terraform/staging/
  # #   steps:
  # #     - name: Git checkout
  # #       uses: actions/checkout@v3

  # #     - name: Define sleep time in minutes
  # #       id: define_sleep
  # #       run: echo "sleep_minutes=$(( ${{ vars.DESTROY_AWS_STAGING_ENV_RESOURCES_AFTER_SECONDS }} / 60 ))" >> $GITHUB_ENV

  # #     - name: Wait for ${{ env.sleep_minutes }} minutes
  # #       run: sleep ${{ vars.DESTROY_AWS_STAGING_ENV_RESOURCES_AFTER_SECONDS }}

  # #     - name: Configure AWS credentials from AWS account
  # #       uses: aws-actions/configure-aws-credentials@v1
  # #       with:
  # #         role-to-assume: ${{ secrets.AWS_ROLE }}
  # #         aws-region: ${{ secrets.AWS_REGION }}
  # #         role-session-name: GitHub-OIDC-TERRAFORM

  # #     - name: Setup Terraform
  # #       uses: hashicorp/setup-terraform@v2
  # #       with:
  # #         terraform_version: 1.2.5

  # #     - name: Terraform Init
  # #       id: init
  # #       env:
  # #         AWS_BUCKET_NAME: ${{ secrets.AWS_TF_STATE_S3_BUCKET_NAME }}
  # #         AWS_BUCKET_KEY_NAME: ${{ secrets.AWS_TF_STATE_S3_BUCKET_KEY_NAME }}
  # #       run: terraform init -backend-config="bucket=${AWS_BUCKET_NAME}" -backend-config="key=${AWS_BUCKET_KEY_NAME}" -backend-config="region=${AWS_REGION}"

  # #     - name: Terraform Destroy
  # #       run: terraform destroy -auto-approve -input=false
